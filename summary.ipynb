{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0hSW-GvfuOjE"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torchsummary import summary\n","from amp import AMP\n","\n","\n","import os\n","import argparse"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OPbPTfKvuOjH"},"outputs":[],"source":["\n","class Block(nn.Module):\n","    '''Grouped convolution block.'''\n","    expansion = 2\n","\n","    def __init__(self, in_planes, cardinality=32, bottleneck_width=4, stride=1):\n","        super(Block, self).__init__()\n","        group_width = cardinality * bottleneck_width\n","        self.conv1 = nn.Conv2d(in_planes, group_width, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(group_width)\n","        self.conv2 = nn.Conv2d(group_width, group_width, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n","        self.bn2 = nn.BatchNorm2d(group_width)\n","        self.conv3 = nn.Conv2d(group_width, self.expansion*group_width, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*group_width)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*group_width:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*group_width, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*group_width)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNeXt(nn.Module):\n","    def __init__(self, num_blocks, cardinality, bottleneck_width, num_classes=10):\n","        super(ResNeXt, self).__init__()\n","        self.cardinality = cardinality\n","        self.bottleneck_width = bottleneck_width\n","        self.in_planes = 32\n","\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.layer1 = self._make_layer(num_blocks[0], 1)\n","        self.layer2 = self._make_layer(num_blocks[1], 2)\n","        self.layer3 = self._make_layer(num_blocks[2], 2)\n","        # self.layer4 = self._make_layer(num_blocks[3], 2)\n","        self.linear = nn.Linear(cardinality*bottleneck_width*8, num_classes)\n","\n","    def _make_layer(self, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(Block(self.in_planes, self.cardinality, self.bottleneck_width, stride))\n","            self.in_planes = Block.expansion * self.cardinality * self.bottleneck_width\n","        # Increase bottleneck_width by 2 after each stage.\n","        self.bottleneck_width *= 2\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        # out = self.layer4(out)\n","        out = F.avg_pool2d(out, 8)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def MyResNeXt():\n","    return ResNeXt(num_blocks=[3,3,3], cardinality=32, bottleneck_width=4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wwlcxhFFuOjI","outputId":"0de32c4e-db6b-4245-9576-4b981e34afd0"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 32, 32]              96\n","       BatchNorm2d-2           [-1, 32, 32, 32]              64\n","            Conv2d-3          [-1, 128, 32, 32]           4,096\n","       BatchNorm2d-4          [-1, 128, 32, 32]             256\n","            Conv2d-5          [-1, 128, 32, 32]           4,608\n","       BatchNorm2d-6          [-1, 128, 32, 32]             256\n","            Conv2d-7          [-1, 256, 32, 32]          32,768\n","       BatchNorm2d-8          [-1, 256, 32, 32]             512\n","            Conv2d-9          [-1, 256, 32, 32]           8,192\n","      BatchNorm2d-10          [-1, 256, 32, 32]             512\n","            Block-11          [-1, 256, 32, 32]               0\n","           Conv2d-12          [-1, 128, 32, 32]          32,768\n","      BatchNorm2d-13          [-1, 128, 32, 32]             256\n","           Conv2d-14          [-1, 128, 32, 32]           4,608\n","      BatchNorm2d-15          [-1, 128, 32, 32]             256\n","           Conv2d-16          [-1, 256, 32, 32]          32,768\n","      BatchNorm2d-17          [-1, 256, 32, 32]             512\n","            Block-18          [-1, 256, 32, 32]               0\n","           Conv2d-19          [-1, 128, 32, 32]          32,768\n","      BatchNorm2d-20          [-1, 128, 32, 32]             256\n","           Conv2d-21          [-1, 128, 32, 32]           4,608\n","      BatchNorm2d-22          [-1, 128, 32, 32]             256\n","           Conv2d-23          [-1, 256, 32, 32]          32,768\n","      BatchNorm2d-24          [-1, 256, 32, 32]             512\n","            Block-25          [-1, 256, 32, 32]               0\n","           Conv2d-26          [-1, 256, 32, 32]          65,536\n","      BatchNorm2d-27          [-1, 256, 32, 32]             512\n","           Conv2d-28          [-1, 256, 16, 16]          18,432\n","      BatchNorm2d-29          [-1, 256, 16, 16]             512\n","           Conv2d-30          [-1, 512, 16, 16]         131,072\n","      BatchNorm2d-31          [-1, 512, 16, 16]           1,024\n","           Conv2d-32          [-1, 512, 16, 16]         131,072\n","      BatchNorm2d-33          [-1, 512, 16, 16]           1,024\n","            Block-34          [-1, 512, 16, 16]               0\n","           Conv2d-35          [-1, 256, 16, 16]         131,072\n","      BatchNorm2d-36          [-1, 256, 16, 16]             512\n","           Conv2d-37          [-1, 256, 16, 16]          18,432\n","      BatchNorm2d-38          [-1, 256, 16, 16]             512\n","           Conv2d-39          [-1, 512, 16, 16]         131,072\n","      BatchNorm2d-40          [-1, 512, 16, 16]           1,024\n","            Block-41          [-1, 512, 16, 16]               0\n","           Conv2d-42          [-1, 256, 16, 16]         131,072\n","      BatchNorm2d-43          [-1, 256, 16, 16]             512\n","           Conv2d-44          [-1, 256, 16, 16]          18,432\n","      BatchNorm2d-45          [-1, 256, 16, 16]             512\n","           Conv2d-46          [-1, 512, 16, 16]         131,072\n","      BatchNorm2d-47          [-1, 512, 16, 16]           1,024\n","            Block-48          [-1, 512, 16, 16]               0\n","           Conv2d-49          [-1, 512, 16, 16]         262,144\n","      BatchNorm2d-50          [-1, 512, 16, 16]           1,024\n","           Conv2d-51            [-1, 512, 8, 8]          73,728\n","      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n","           Conv2d-53           [-1, 1024, 8, 8]         524,288\n","      BatchNorm2d-54           [-1, 1024, 8, 8]           2,048\n","           Conv2d-55           [-1, 1024, 8, 8]         524,288\n","      BatchNorm2d-56           [-1, 1024, 8, 8]           2,048\n","            Block-57           [-1, 1024, 8, 8]               0\n","           Conv2d-58            [-1, 512, 8, 8]         524,288\n","      BatchNorm2d-59            [-1, 512, 8, 8]           1,024\n","           Conv2d-60            [-1, 512, 8, 8]          73,728\n","      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n","           Conv2d-62           [-1, 1024, 8, 8]         524,288\n","      BatchNorm2d-63           [-1, 1024, 8, 8]           2,048\n","            Block-64           [-1, 1024, 8, 8]               0\n","           Conv2d-65            [-1, 512, 8, 8]         524,288\n","      BatchNorm2d-66            [-1, 512, 8, 8]           1,024\n","           Conv2d-67            [-1, 512, 8, 8]          73,728\n","      BatchNorm2d-68            [-1, 512, 8, 8]           1,024\n","           Conv2d-69           [-1, 1024, 8, 8]         524,288\n","      BatchNorm2d-70           [-1, 1024, 8, 8]           2,048\n","            Block-71           [-1, 1024, 8, 8]               0\n","           Linear-72                   [-1, 10]          10,250\n","================================================================\n","Total params: 4,761,770\n","Trainable params: 4,761,770\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 64.50\n","Params size (MB): 18.16\n","Estimated Total Size (MB): 82.68\n","----------------------------------------------------------------\n"]}],"source":["python your_script.py > model_summary.txt\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = MyResNeXt().to(device)\n","summary(model, (3, 32, 32))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_odymPXuOjJ","executionInfo":{"status":"error","timestamp":1681516176453,"user_tz":240,"elapsed":167,"user":{"displayName":"Pranav Doma","userId":"13927259988215563414"}},"outputId":"aa78b73b-019c-406c-f78a-a251b8ebc945","colab":{"base_uri":"https://localhost:8080/","height":130}},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-545e3113ab80>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python your_script.py > model_summary.txt\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["python your_script.py > model_summary.txt\n"]}],"metadata":{"kernelspec":{"display_name":"my_env","language":"python","name":"my_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}